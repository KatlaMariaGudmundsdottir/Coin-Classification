{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Segmentation for Coin Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski  # Image handling library\n",
    "import numpy as np  # Basic array handling\n",
    "import matplotlib.pyplot as plt  # Plotting results\n",
    "import os  # Dealing with paths and loading images\n",
    "import cv2 as cv\n",
    "\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in images\n",
    "This is only for loading in training data as given in the correct format of the Kaggle challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = \"../Data/train\"\n",
    "train_folders = sorted(os.listdir(path_to_train))\n",
    "\n",
    "# Load in all images from the training set into this dictionary\n",
    "train_images_grouped = {}\n",
    "\n",
    "for folder in train_folders:\n",
    "    train_images = []\n",
    "    folder_path = os.path.join(path_to_train, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    images = os.listdir(folder_path)\n",
    "    for image in images:\n",
    "        image_path = os.path.join(folder_path, image)\n",
    "        loaded_image = cv.imread(image_path)\n",
    "        loaded_image = cv.cvtColor(loaded_image, cv.COLOR_BGR2RGB) \n",
    "        train_images.append(loaded_image)\n",
    "    folder = folder.replace(\" \", \"\")  # Remove whitespace\n",
    "    import re\n",
    "    folder = re.sub(\"[0-9.]\", \"\", folder) # Remove numbers and '.'\n",
    "    train_images_grouped[str(folder)] = train_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 2\n",
    "# Load in the first image of each class as a sample, test image\n",
    "neutral_bg_sample = train_images_grouped[\"neutral_bg\"][image_num]\n",
    "noisy_bg_sample = train_images_grouped[\"noisy_bg\"][image_num]\n",
    "hand_bg_sample = train_images_grouped[\"hand\"][image_num]\n",
    "neutral_bg_sample_ood = train_images_grouped[\"neutral_bg_outliers\"][image_num]\n",
    "noisy_bg_sample_ood = train_images_grouped[\"noisy_bg_outliers\"][image_num]\n",
    "hand_bg_sample_ood = train_images_grouped[\"hand_outliers\"][image_num]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "Here we check if the number of training images loaded for each class is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0 \n",
    "for group in train_images_grouped:\n",
    "    group_len = len(train_images_grouped[group])\n",
    "    N += group_len\n",
    "    print(f\"Group name: '{group}' \\n with length: {group_len} \\n\")\n",
    "\n",
    "print(f\"N: {N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gimp2opencvHSV(h, s, v):\n",
    "    \"\"\"\n",
    "    Convert GIMP HSV values to OpenCV HSV values.\n",
    "    GIMP uses the range [0, 360] for H, [0, 100] for S and V.\n",
    "    OpenCV uses the range [0, 180] for H, [0, 255] for S and V.\n",
    "    \"\"\"\n",
    "    return 180 * (h / 260), 255 * (s / 100), 255 * (v / 100)\n",
    "\n",
    "def extract_hsv_channels(image):\n",
    "    \"\"\"\n",
    "    Extracts the HSV channels from an image.\n",
    "    \"\"\"\n",
    "    hsv_image = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
    "    h, s, v = cv.split(hsv_image)\n",
    "    return h, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing filters to separate coins from neutral, noisy and hand backgrounds\n",
    "def get_contours(img_original):\n",
    "    img = img_original.copy()\n",
    "\n",
    "    h, s, v = extract_hsv_channels(img)\n",
    "\n",
    "    # The following conversions are from GIMP to OpenCV\n",
    "    # GIMP uses (360, 100, 100), OpenCV uses (180, 255, 255)\n",
    "    h_upper = 180 * (65 / 360)\n",
    "    h_lower = 180 * (18 / 360)\n",
    "\n",
    "    s_upper = 255 * (85 / 100)\n",
    "    s_lower = 255 * (10 / 100)\n",
    "\n",
    "    v_upper = 255 * (95 / 100)\n",
    "    v_lower = 255 * (40 / 100)\n",
    "\n",
    "    # Use the above range to create another HSV image\n",
    "    img = cv.cvtColor(img, cv.COLOR_RGB2HSV)\n",
    "\n",
    "    # Main thresholding for background separation\n",
    "    img_thres = cv.inRange(\n",
    "        img, (h_lower, s_lower, v_lower), (h_upper, s_upper, v_upper)\n",
    "    )\n",
    "\n",
    "    # Additional mask for dimly lit background \n",
    "    background_mask = cv.inRange(img, (180 * 32/360, 255 * 12/100, 255 * 72/100), (180 * 38/360, 255 * 28/100, 255 * 78/100))\n",
    "\n",
    "    # Additional mask for light silver coins\n",
    "    light_silver_coin_mask = cv.inRange(img, gimp2opencvHSV(190, 6.2, 72.3), gimp2opencvHSV(205, 10.3, 81.2))\n",
    "\n",
    "\n",
    "    img[img_thres == 0 & ~(light_silver_coin_mask == 255)] = 0\n",
    "    img[background_mask == 255] = 0\n",
    "\n",
    "    img = cv.cvtColor(img, cv.COLOR_HSV2RGB)\n",
    "\n",
    "    # return img\n",
    "\n",
    "    # Convert to grayscale\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    ret, img_thresh_gray = cv.threshold(\n",
    "        img_gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    thresh = cv.bitwise_not(img_thresh_gray)\n",
    "\n",
    "    # Closing small holes\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    thresh = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel, iterations=5)\n",
    "\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    thresh = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel, iterations=8)\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    thresh = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel, iterations=5)\n",
    "\n",
    "    # return thresh\n",
    "\n",
    "    sure_bg = cv.dilate(thresh, kernel, iterations=8)\n",
    "\n",
    "    dist_transform = cv.distanceTransform(thresh, cv.DIST_L2, 5)\n",
    "\n",
    "    # return dist_transform\n",
    "\n",
    "    ret, sure_fg = cv.threshold(dist_transform, 0.2 * dist_transform.max(), 255, 0)\n",
    "\n",
    "    # return sure_fg\n",
    "\n",
    "    kernel = np.ones((16, 16), np.uint8)\n",
    "    sure_fg = cv.erode(sure_fg, kernel, iterations=8)\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    sure_fg = cv.dilate(sure_fg, kernel, iterations=4)\n",
    "\n",
    "    # return sure_fg\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    # Connected Components determines the connectivity of blob-like regions in a binary image.\n",
    "    ret, markers = cv.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    markers = cv.watershed(img, markers)\n",
    "    img[markers == -1] = [255, 0, 0]  # Optionally mark -1 boundaries if needed\n",
    "\n",
    "    # Create an output image to draw on\n",
    "    output_img = img_original.copy()\n",
    "\n",
    "    all_contours = []\n",
    "    # Process each region\n",
    "    for label in np.unique(markers):\n",
    "        if label == 0 or label == 1:  # Background or borders\n",
    "            continue\n",
    "\n",
    "        # Create a mask for the current region\n",
    "        mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "        mask[markers == label] = 255\n",
    "\n",
    "        # Find contours and get the bounding box\n",
    "        contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        # print(f\"Length of contours: {len(contours)}\")\n",
    "        for cntr in contours:\n",
    "            area = cv.contourArea(cntr)\n",
    "\n",
    "            # Check if contour is big enough\n",
    "            if area < 70000 or area > 700000:\n",
    "                continue\n",
    "\n",
    "            # # Check if contour is \"cirular\" enough\n",
    "            # perimeter = cv.arcLength(cntr, True)\n",
    "\n",
    "            # # Calculate circularity\n",
    "            # if perimeter == 0:\n",
    "            #     continue  # Avoid division by zero\n",
    "\n",
    "            # circularity = 4 * np.pi * (area / (perimeter**2))\n",
    "\n",
    "            # if circularity < 0.1:\n",
    "            #     continue\n",
    "\n",
    "            # # Calculate convexity\n",
    "            # hull = cv.convexHull(cntr)\n",
    "            # hull_area = cv.contourArea(hull)\n",
    "\n",
    "            # if hull_area == 0:\n",
    "            #     continue\n",
    "            # convexity = area / hull_area\n",
    "\n",
    "            # if convexity < 0.8:\n",
    "            #     continue\n",
    "\n",
    "            # Calculate bounding box\n",
    "            x, y, w, h = cv.boundingRect(cntr)\n",
    "            # Draw bounding box\n",
    "            cv.rectangle(output_img, (x, y), (x + w, y + h), (255, 0, 0), 15)\n",
    "\n",
    "            # Draw contour (optional)\n",
    "            # cv.drawContours(output_img, [cntr], -1, (0, 0, 255), 2)\n",
    "            \n",
    "            all_contours.append(cntr)\n",
    "\n",
    "    return output_img, all_contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_IMAGES = 6\n",
    "for image_num in range(6):\n",
    "    neutral_bg_sample = train_images_grouped[\"neutral_bg\"][image_num]\n",
    "    noisy_bg_sample = train_images_grouped[\"noisy_bg\"][image_num]\n",
    "    hand_bg_sample = train_images_grouped[\"hand\"][image_num]\n",
    "    neutral_bg_sample_ood = train_images_grouped[\"neutral_bg_outliers\"][image_num]\n",
    "    noisy_bg_sample_ood = train_images_grouped[\"noisy_bg_outliers\"][image_num]\n",
    "    hand_bg_sample_ood = train_images_grouped[\"hand_outliers\"][image_num]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(get_contours(neutral_bg_sample)[0])\n",
    "    plt.title(\"Neutral background\")\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(get_contours(noisy_bg_sample)[0])\n",
    "    plt.title(\"Noisy background\")\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(get_contours(hand_bg_sample)[0])\n",
    "    plt.title(\"Hand background\")\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(get_contours(neutral_bg_sample_ood)[0])\n",
    "    plt.title(\"Neutral background\")\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(get_contours(noisy_bg_sample_ood)[0])\n",
    "    plt.title(\"Noisy background\")\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.imshow(get_contours(hand_bg_sample_ood)[0])\n",
    "    plt.title(\"Hand background\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the bounding boxes from the images\n",
    "def crop_bounding_boxes(img_original, contours):\n",
    "    '''\n",
    "    Takes in an image with multiple coins and its contours that represent the coins.\n",
    "    Outputs a list of cropped images.\n",
    "    '''\n",
    "\n",
    "    img = img_original.copy()\n",
    "    cropped_images = []\n",
    "\n",
    "    for cntr in contours:\n",
    "        area = cv.contourArea(cntr)\n",
    "\n",
    "        # Check if contour is big enough\n",
    "        if area < 70000 or area > 700000:\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = cv.boundingRect(cntr)\n",
    "        cropped_images.append(img[y:y+h, x:x+w])\n",
    "\n",
    "    return cropped_images\n",
    "\n",
    "# Apply filters\n",
    "noisy_bg_sample_filtered, contours = get_contours(noisy_bg_sample)\n",
    "\n",
    "# Remember to pass in the original image, otherwise we get the red bounding boxes as well\n",
    "cropped_coins = crop_bounding_boxes(noisy_bg_sample, contours)\n",
    "\n",
    "# Plot the cropped coins\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, coin in enumerate(cropped_coins):\n",
    "    plt.subplot(1, len(cropped_coins), i+1)\n",
    "    plt.imshow(coin)\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
